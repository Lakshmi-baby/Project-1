import requests
from bs4 import BeautifulSoup
import csv

def scrape_website(url):
    # Send a GET request to the URL
    response = requests.get(url)

    if response.status_code == 200:
        # Parse the HTML content of the page
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract product information (replace with actual HTML structure)
        product_names = soup.find_all('div', class_='product-name')
        product_prices = soup.find_all('span', class_='product-price')
        product_ratings = soup.find_all('div', class_='product-rating')

        # Create a list to store the extracted data
        data = []

        # Iterate through the product information and store in the list
        for name, price, rating in zip(product_names, product_prices, product_ratings):
            data.append({
                'Name': name.text.strip(),
                'Price': price.text.strip(),
                'Rating': rating.text.strip()
            })

        # Write the data to a CSV file
        with open('product_data.csv', 'w', newline='') as csvfile:
            fieldnames = ['Name', 'Price', 'Rating']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            # Write header
            writer.writeheader()

            # Write data
            for product in data:
                writer.writerow(product)

        print("Data scraped successfully and stored in 'product_data.csv'.")
    else:
        print(f"Failed to retrieve data. Status code: {response.status_code}")

# Replace the URL with the actual website URL you have permission to scrape
website_url = 'https://example.com/products'
scrape_website(website_url)
